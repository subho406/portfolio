@article{PRAMANIK201915,
 abstract = {We perform text normalization, i.e. the transformation of words from the written to the spoken form, using a memory augmented neural network. With the addition of dynamic memory access and storage mechanism, we present a neural architecture that will serve as a language-agnostic text normalization system while avoiding the kind of unacceptable errors made by the LSTM-based recurrent neural networks. By successfully reducing the frequency of such mistakes, we show that this novel architecture is indeed a better alternative. Our proposed system requires significantly lesser amounts of data, training time and compute resources. Additionally, we perform data up-sampling, circumventing the data sparsity problem in some semiotic classes, to show that sufficient examples in any particular class can improve the performance of our text normalization system. Although a few occurrences of these errors still remain in certain semiotic classes, we demonstrate that memory augmented networks with meta-learning capabilities can open many doors to a superior text normalization system.},
 author = {Subhojeet Pramanik and Aman Hussain},
 doi = {https://doi.org/10.1016/j.specom.2019.02.003},
 issn = {0167-6393},
 journal = {Speech Communication},
 keywords = {Text normalization, Differentiable Neural Computer, Deep learning},
 pages = {15 - 23},
 title = {Text normalization using memory augmented neural networks},
 url = {http://www.sciencedirect.com/science/article/pii/S0167639318302395},
 volume = {109},
 year = {2019}
}

